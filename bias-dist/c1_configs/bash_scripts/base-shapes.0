# This is a base shape file encoded in yaml
# - `null` indicates a dimension is "finite", i.e. a non-"width" dimension
# - a number indicates the base dimension of an "infinite" dimension, i.e. some notion of "width"
sequential.0.word_embeddings.weight:
- null
- 768
sequential.10.attention.dense.bias:
- 768
sequential.10.attention.dense.weight:
- 768
- 768
sequential.10.attention.query_key_value.bias:
- 2304
sequential.10.attention.query_key_value.weight:
- 2304
- 768
sequential.10.input_layernorm.bias:
- 768
sequential.10.input_layernorm.weight:
- 768
sequential.10.mlp.experts.experts_embedding.h_down:
- 3840
- null
sequential.10.mlp.experts.experts_embedding.h_up:
- 3840
- null
sequential.10.mlp.experts.mlp.hn_down:
- 3840
- null
sequential.10.mlp.experts.mlp.hn_up:
- 3840
- null
sequential.10.mlp.experts.mlp.hn_up_w1:
- 1792
- 30720
sequential.10.mlp.experts.mlp.hn_up_w2:
- 1792
- 30720
sequential.10.mlp.experts.mlp.w1:
- null
- 768
sequential.10.mlp.experts.mlp.w2:
- null
- 768
sequential.10.mlp.router.layer.weight:
- null
- 768
sequential.10.post_attention_layernorm.bias:
- 768
sequential.10.post_attention_layernorm.weight:
- 768
sequential.11.attention.dense.bias:
- 768
sequential.11.attention.dense.weight:
- 768
- 768
sequential.11.attention.query_key_value.bias:
- 2304
sequential.11.attention.query_key_value.weight:
- 2304
- 768
sequential.11.input_layernorm.bias:
- 768
sequential.11.input_layernorm.weight:
- 768
sequential.11.mlp.experts.experts_embedding.h_down:
- 3840
- null
sequential.11.mlp.experts.experts_embedding.h_up:
- 3840
- null
sequential.11.mlp.experts.mlp.hn_down:
- 3840
- null
sequential.11.mlp.experts.mlp.hn_up:
- 3840
- null
sequential.11.mlp.experts.mlp.hn_up_w1:
- 1792
- 30720
sequential.11.mlp.experts.mlp.hn_up_w2:
- 1792
- 30720
sequential.11.mlp.experts.mlp.w1:
- null
- 768
sequential.11.mlp.experts.mlp.w2:
- null
- 768
sequential.11.mlp.router.layer.weight:
- null
- 768
sequential.11.post_attention_layernorm.bias:
- 768
sequential.11.post_attention_layernorm.weight:
- 768
sequential.12.attention.dense.bias:
- 768
sequential.12.attention.dense.weight:
- 768
- 768
sequential.12.attention.query_key_value.bias:
- 2304
sequential.12.attention.query_key_value.weight:
- 2304
- 768
sequential.12.input_layernorm.bias:
- 768
sequential.12.input_layernorm.weight:
- 768
sequential.12.mlp.experts.experts_embedding.h_down:
- 3840
- null
sequential.12.mlp.experts.experts_embedding.h_up:
- 3840
- null
sequential.12.mlp.experts.mlp.hn_down:
- 3840
- null
sequential.12.mlp.experts.mlp.hn_up:
- 3840
- null
sequential.12.mlp.experts.mlp.hn_up_w1:
- 1792
- 30720
sequential.12.mlp.experts.mlp.hn_up_w2:
- 1792
- 30720
sequential.12.mlp.experts.mlp.w1:
- null
- 768
sequential.12.mlp.experts.mlp.w2:
- null
- 768
sequential.12.mlp.router.layer.weight:
- null
- 768
sequential.12.post_attention_layernorm.bias:
- 768
sequential.12.post_attention_layernorm.weight:
- 768
sequential.13.attention.dense.bias:
- 768
sequential.13.attention.dense.weight:
- 768
- 768
sequential.13.attention.query_key_value.bias:
- 2304
sequential.13.attention.query_key_value.weight:
- 2304
- 768
sequential.13.input_layernorm.bias:
- 768
sequential.13.input_layernorm.weight:
- 768
sequential.13.mlp.experts.experts_embedding.h_down:
- 3840
- null
sequential.13.mlp.experts.experts_embedding.h_up:
- 3840
- null
sequential.13.mlp.experts.mlp.hn_down:
- 3840
- null
sequential.13.mlp.experts.mlp.hn_up:
- 3840
- null
sequential.13.mlp.experts.mlp.hn_up_w1:
- 1792
- 30720
sequential.13.mlp.experts.mlp.hn_up_w2:
- 1792
- 30720
sequential.13.mlp.experts.mlp.w1:
- null
- 768
sequential.13.mlp.experts.mlp.w2:
- null
- 768
sequential.13.mlp.router.layer.weight:
- null
- 768
sequential.13.post_attention_layernorm.bias:
- 768
sequential.13.post_attention_layernorm.weight:
- 768
sequential.15.norm.bias:
- 768
sequential.15.norm.weight:
- 768
sequential.16.final_linear.weight:
- null
- 768
sequential.2.attention.dense.bias:
- 768
sequential.2.attention.dense.weight:
- 768
- 768
sequential.2.attention.query_key_value.bias:
- 2304
sequential.2.attention.query_key_value.weight:
- 2304
- 768
sequential.2.input_layernorm.bias:
- 768
sequential.2.input_layernorm.weight:
- 768
sequential.2.mlp.experts.experts_embedding.h_down:
- 3840
- null
sequential.2.mlp.experts.experts_embedding.h_up:
- 3840
- null
sequential.2.mlp.experts.mlp.hn_down:
- 3840
- null
sequential.2.mlp.experts.mlp.hn_up:
- 3840
- null
sequential.2.mlp.experts.mlp.hn_up_w1:
- 1792
- 30720
sequential.2.mlp.experts.mlp.hn_up_w2:
- 1792
- 30720
sequential.2.mlp.experts.mlp.w1:
- null
- 768
sequential.2.mlp.experts.mlp.w2:
- null
- 768
sequential.2.mlp.router.layer.weight:
- null
- 768
sequential.2.post_attention_layernorm.bias:
- 768
sequential.2.post_attention_layernorm.weight:
- 768
sequential.3.attention.dense.bias:
- 768
sequential.3.attention.dense.weight:
- 768
- 768
sequential.3.attention.query_key_value.bias:
- 2304
sequential.3.attention.query_key_value.weight:
- 2304
- 768
sequential.3.input_layernorm.bias:
- 768
sequential.3.input_layernorm.weight:
- 768
sequential.3.mlp.experts.experts_embedding.h_down:
- 3840
- null
sequential.3.mlp.experts.experts_embedding.h_up:
- 3840
- null
sequential.3.mlp.experts.mlp.hn_down:
- 3840
- null
sequential.3.mlp.experts.mlp.hn_up:
- 3840
- null
sequential.3.mlp.experts.mlp.hn_up_w1:
- 1792
- 30720
sequential.3.mlp.experts.mlp.hn_up_w2:
- 1792
- 30720
sequential.3.mlp.experts.mlp.w1:
- null
- 768
sequential.3.mlp.experts.mlp.w2:
- null
- 768
sequential.3.mlp.router.layer.weight:
- null
- 768
sequential.3.post_attention_layernorm.bias:
- 768
sequential.3.post_attention_layernorm.weight:
- 768
sequential.4.attention.dense.bias:
- 768
sequential.4.attention.dense.weight:
- 768
- 768
sequential.4.attention.query_key_value.bias:
- 2304
sequential.4.attention.query_key_value.weight:
- 2304
- 768
sequential.4.input_layernorm.bias:
- 768
sequential.4.input_layernorm.weight:
- 768
sequential.4.mlp.experts.experts_embedding.h_down:
- 3840
- null
sequential.4.mlp.experts.experts_embedding.h_up:
- 3840
- null
sequential.4.mlp.experts.mlp.hn_down:
- 3840
- null
sequential.4.mlp.experts.mlp.hn_up:
- 3840
- null
sequential.4.mlp.experts.mlp.hn_up_w1:
- 1792
- 30720
sequential.4.mlp.experts.mlp.hn_up_w2:
- 1792
- 30720
sequential.4.mlp.experts.mlp.w1:
- null
- 768
sequential.4.mlp.experts.mlp.w2:
- null
- 768
sequential.4.mlp.router.layer.weight:
- null
- 768
sequential.4.post_attention_layernorm.bias:
- 768
sequential.4.post_attention_layernorm.weight:
- 768
sequential.5.attention.dense.bias:
- 768
sequential.5.attention.dense.weight:
- 768
- 768
sequential.5.attention.query_key_value.bias:
- 2304
sequential.5.attention.query_key_value.weight:
- 2304
- 768
sequential.5.input_layernorm.bias:
- 768
sequential.5.input_layernorm.weight:
- 768
sequential.5.mlp.experts.experts_embedding.h_down:
- 3840
- null
sequential.5.mlp.experts.experts_embedding.h_up:
- 3840
- null
sequential.5.mlp.experts.mlp.hn_down:
- 3840
- null
sequential.5.mlp.experts.mlp.hn_up:
- 3840
- null
sequential.5.mlp.experts.mlp.hn_up_w1:
- 1792
- 30720
sequential.5.mlp.experts.mlp.hn_up_w2:
- 1792
- 30720
sequential.5.mlp.experts.mlp.w1:
- null
- 768
sequential.5.mlp.experts.mlp.w2:
- null
- 768
sequential.5.mlp.router.layer.weight:
- null
- 768
sequential.5.post_attention_layernorm.bias:
- 768
sequential.5.post_attention_layernorm.weight:
- 768
sequential.6.attention.dense.bias:
- 768
sequential.6.attention.dense.weight:
- 768
- 768
sequential.6.attention.query_key_value.bias:
- 2304
sequential.6.attention.query_key_value.weight:
- 2304
- 768
sequential.6.input_layernorm.bias:
- 768
sequential.6.input_layernorm.weight:
- 768
sequential.6.mlp.experts.experts_embedding.h_down:
- 3840
- null
sequential.6.mlp.experts.experts_embedding.h_up:
- 3840
- null
sequential.6.mlp.experts.mlp.hn_down:
- 3840
- null
sequential.6.mlp.experts.mlp.hn_up:
- 3840
- null
sequential.6.mlp.experts.mlp.hn_up_w1:
- 1792
- 30720
sequential.6.mlp.experts.mlp.hn_up_w2:
- 1792
- 30720
sequential.6.mlp.experts.mlp.w1:
- null
- 768
sequential.6.mlp.experts.mlp.w2:
- null
- 768
sequential.6.mlp.router.layer.weight:
- null
- 768
sequential.6.post_attention_layernorm.bias:
- 768
sequential.6.post_attention_layernorm.weight:
- 768
sequential.7.attention.dense.bias:
- 768
sequential.7.attention.dense.weight:
- 768
- 768
sequential.7.attention.query_key_value.bias:
- 2304
sequential.7.attention.query_key_value.weight:
- 2304
- 768
sequential.7.input_layernorm.bias:
- 768
sequential.7.input_layernorm.weight:
- 768
sequential.7.mlp.experts.experts_embedding.h_down:
- 3840
- null
sequential.7.mlp.experts.experts_embedding.h_up:
- 3840
- null
sequential.7.mlp.experts.mlp.hn_down:
- 3840
- null
sequential.7.mlp.experts.mlp.hn_up:
- 3840
- null
sequential.7.mlp.experts.mlp.hn_up_w1:
- 1792
- 30720
sequential.7.mlp.experts.mlp.hn_up_w2:
- 1792
- 30720
sequential.7.mlp.experts.mlp.w1:
- null
- 768
sequential.7.mlp.experts.mlp.w2:
- null
- 768
sequential.7.mlp.router.layer.weight:
- null
- 768
sequential.7.post_attention_layernorm.bias:
- 768
sequential.7.post_attention_layernorm.weight:
- 768
sequential.8.attention.dense.bias:
- 768
sequential.8.attention.dense.weight:
- 768
- 768
sequential.8.attention.query_key_value.bias:
- 2304
sequential.8.attention.query_key_value.weight:
- 2304
- 768
sequential.8.input_layernorm.bias:
- 768
sequential.8.input_layernorm.weight:
- 768
sequential.8.mlp.experts.experts_embedding.h_down:
- 3840
- null
sequential.8.mlp.experts.experts_embedding.h_up:
- 3840
- null
sequential.8.mlp.experts.mlp.hn_down:
- 3840
- null
sequential.8.mlp.experts.mlp.hn_up:
- 3840
- null
sequential.8.mlp.experts.mlp.hn_up_w1:
- 1792
- 30720
sequential.8.mlp.experts.mlp.hn_up_w2:
- 1792
- 30720
sequential.8.mlp.experts.mlp.w1:
- null
- 768
sequential.8.mlp.experts.mlp.w2:
- null
- 768
sequential.8.mlp.router.layer.weight:
- null
- 768
sequential.8.post_attention_layernorm.bias:
- 768
sequential.8.post_attention_layernorm.weight:
- 768
sequential.9.attention.dense.bias:
- 768
sequential.9.attention.dense.weight:
- 768
- 768
sequential.9.attention.query_key_value.bias:
- 2304
sequential.9.attention.query_key_value.weight:
- 2304
- 768
sequential.9.input_layernorm.bias:
- 768
sequential.9.input_layernorm.weight:
- 768
sequential.9.mlp.experts.experts_embedding.h_down:
- 3840
- null
sequential.9.mlp.experts.experts_embedding.h_up:
- 3840
- null
sequential.9.mlp.experts.mlp.hn_down:
- 3840
- null
sequential.9.mlp.experts.mlp.hn_up:
- 3840
- null
sequential.9.mlp.experts.mlp.hn_up_w1:
- 1792
- 30720
sequential.9.mlp.experts.mlp.hn_up_w2:
- 1792
- 30720
sequential.9.mlp.experts.mlp.w1:
- null
- 768
sequential.9.mlp.experts.mlp.w2:
- null
- 768
sequential.9.mlp.router.layer.weight:
- null
- 768
sequential.9.post_attention_layernorm.bias:
- 768
sequential.9.post_attention_layernorm.weight:
- 768
